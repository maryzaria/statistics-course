{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0052e952",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "resp = urlopen('file:///C:/Users/user/PycharmProjects/pythonProject/html14.txt') # скачиваем файл\n",
    "html = resp.read() # считываем содержимое\n",
    "soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "#table = soup.find('table', attrs = {'class' : 'wikitable sortable'})\n",
    "cite = []\n",
    "d={}\n",
    "cnt_m = 0\n",
    "for link in soup.find_all('code'):\n",
    "    #print(str(link)[6:-7])\n",
    "    cite.append(str(link)[6:-7])\n",
    "#print(cite)\n",
    "for i in range(len(cite)):\n",
    "    cnt = cite.count(cite[i])\n",
    "    a = cite[i]\n",
    "    d[a] = cnt\n",
    "    if cnt>=cnt_m:\n",
    "        cnt_m=cnt\n",
    "       # print(cite[i])\n",
    "#for i in range(len(d)):\n",
    "\n",
    "\n",
    "for i in range(len(b)):\n",
    "    if int(b[i][1]) == cnt_m:\n",
    "        print(b[i][0], end=' ')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1e6bc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9540e85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wiki/Ahmedabad\n",
      "/wiki/Amsterdam\n",
      "/wiki/Antwerp\n",
      "/wiki/Atheism\n",
      "/wiki/Athens\n",
      "/wiki/Atlanta\n",
      "/wiki/Australia\n",
      "/wiki/Bangalore\n",
      "/wiki/Bangkok\n",
      "/wiki/Barcelona\n",
      "/wiki/Beijing\n",
      "/wiki/Berlin\n",
      "/wiki/Biblioth%C3%A8que_nationale_de_France\n",
      "/wiki/Bogot%C3%A1\n",
      "/wiki/Brazil\n",
      "/wiki/Brussels\n",
      "/wiki/Bucharest\n",
      "/wiki/Budapest\n",
      "/wiki/Buenos_Aires\n",
      "/wiki/Cairo\n",
      "/wiki/Canada\n",
      "/wiki/Capital_city\n",
      "/wiki/Central_Park\n",
      "/wiki/Ch%C5%ABky%C5%8D_metropolitan_area\n",
      "/wiki/Chengdu\n",
      "/wiki/Chennai\n",
      "/wiki/Chicago\n",
      "/wiki/China\n",
      "/wiki/Chinatown\n",
      "/wiki/Chongqing\n",
      "/wiki/Copenhagen\n",
      "/wiki/D%C3%BCsseldorf\n",
      "/wiki/Daylight_saving_time\n",
      "/wiki/Delhi\n",
      "/wiki/Demonym\n",
      "/wiki/Dhaka\n",
      "/wiki/Digital_object_identifier\n",
      "/wiki/Dongguan\n",
      "/wiki/Dubai\n",
      "/wiki/Dublin\n",
      "/wiki/East_Rand\n",
      "/wiki/Edmonton\n",
      "/wiki/Egypt\n",
      "/wiki/Foshan\n",
      "/wiki/France\n",
      "/wiki/Freeway\n",
      "/wiki/Geographic_coordinate_system\n",
      "/wiki/Global_city\n",
      "/wiki/Greater_Buenos_Aires\n",
      "/wiki/Greater_Cairo\n",
      "/wiki/Greater_London_Built-up_Area\n",
      "/wiki/Greater_Los_Angeles\n",
      "/wiki/Greater_Rio_de_Janeiro\n",
      "/wiki/Greater_Taipei\n",
      "/wiki/Greater_Tehran\n",
      "/wiki/Greater_Tokyo_Area\n",
      "/wiki/Greece\n",
      "/wiki/Guangzhou\n",
      "/wiki/Hanoi\n",
      "/wiki/Helsinki\n",
      "/wiki/Ho_Chi_Minh_City\n",
      "/wiki/Humid_continental_climate\n",
      "/wiki/Hyderabad\n",
      "/wiki/Iceland\n",
      "/wiki/Integrated_Authority_File\n",
      "/wiki/International_Standard_Book_Number\n",
      "/wiki/Israel\n",
      "/wiki/Istanbul\n",
      "/wiki/Italy\n",
      "/wiki/JSTOR\n",
      "/wiki/Jakarta\n",
      "/wiki/Jakarta_metropolitan_area\n",
      "/wiki/Japan\n",
      "/wiki/Johannesburg\n",
      "/wiki/K%C3%B6ppen_climate_classification\n",
      "/wiki/Karachi\n",
      "/wiki/Keihanshin\n",
      "/wiki/Kiev\n",
      "/wiki/Kinshasa\n",
      "/wiki/Klang_Valley\n",
      "/wiki/Kolkata\n",
      "/wiki/Lagos\n",
      "/wiki/Lahore\n",
      "/wiki/Latvia\n",
      "/wiki/Library_of_Congress_Control_Number\n",
      "/wiki/Lima\n",
      "/wiki/Lisbon\n",
      "/wiki/List_of_tallest_buildings_in_the_world\n",
      "/wiki/List_of_urban_areas_by_population\n",
      "/wiki/London\n",
      "/wiki/Los_Angeles\n",
      "/wiki/Madrid\n",
      "/wiki/Main_Page\n",
      "/wiki/Manila\n",
      "/wiki/Megacity\n",
      "/wiki/Melbourne\n",
      "/wiki/Metro_Manila\n",
      "/wiki/Metro_systems_by_annual_passenger_rides\n",
      "/wiki/Mexico\n",
      "/wiki/Mexico_City\n",
      "/wiki/Montreal\n",
      "/wiki/Moscow\n",
      "/wiki/Mumbai\n",
      "/wiki/Munich\n",
      "/wiki/MusicBrainz\n",
      "/wiki/National_Archives_and_Records_Administration\n",
      "/wiki/National_Diet_Library\n",
      "/wiki/National_Library_of_the_Czech_Republic\n",
      "/wiki/Netherlands\n",
      "/wiki/New_York_City\n",
      "/wiki/Onitsha\n",
      "/wiki/Oslo\n",
      "/wiki/Paris\n",
      "/wiki/Peru\n",
      "/wiki/Prague\n",
      "/wiki/Precipitation\n",
      "/wiki/Pristina\n",
      "/wiki/Rapid_transit\n",
      "/wiki/Relative_humidity\n",
      "/wiki/Rio_de_Janeiro\n",
      "/wiki/Rome\n",
      "/wiki/S%C3%A3o_Paulo\n",
      "/wiki/Santiago\n",
      "/wiki/Seoul\n",
      "/wiki/Seoul_Capital_Area\n",
      "/wiki/Shanghai\n",
      "/wiki/Shenyang\n",
      "/wiki/Shenzhen\n",
      "/wiki/Software_development\n",
      "/wiki/South_Korea\n",
      "/wiki/Spain\n",
      "/wiki/Stockholm\n",
      "/wiki/Sunshine_duration\n",
      "/wiki/Sydney\n",
      "/wiki/Tel_Aviv\n",
      "/wiki/The_New_York_Times\n",
      "/wiki/Tianjin\n",
      "/wiki/Time_zone\n",
      "/wiki/Tokyo\n",
      "/wiki/Ultraviolet_index\n",
      "/wiki/United_Kingdom\n",
      "/wiki/United_States\n",
      "/wiki/Urban_area\n",
      "/wiki/Valley_of_Mexico\n",
      "/wiki/Vienna\n",
      "/wiki/Virtual_International_Authority_File\n",
      "/wiki/Warsaw\n",
      "/wiki/West_Germany\n",
      "/wiki/WorldCat_Identities\n",
      "/wiki/World_War_II\n",
      "/wiki/Wuhan\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getlinks(url):\n",
    "    resp = urlopen(url) # скачиваем файл\n",
    "    html = resp.read() # считываем содержимое\n",
    "    soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "    #table = soup.find('table', attrs = {'class' : 'wikitable sortable'})\n",
    "    cnt = 0\n",
    "    d =set()\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.has_attr('href'):\n",
    "            s = link.get('href')\n",
    "            if not (s.startswith('http://') or s.startswith('https://')) and (':' not in s) and (not s.startswith('#')) and (not s.startswith('//')):\n",
    "                    #print(link.get('href'))\n",
    "                if s not in d:\n",
    "                    d.add(s)\n",
    "                \n",
    "    return(d)\n",
    "links1 = getlinks('file:///C:/Users/user/PycharmProjects/pythonProject/html10.txt')\n",
    "links2 = getlinks('file:///C:/Users/user/PycharmProjects/pythonProject/html11.txt')\n",
    "links = links1.intersection(links2)\n",
    "print(('\\n').join(sorted(links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1da7e551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate data for New York (Belvedere Castle, Central Park), 1981–2010 normals,[a] extremes 1869–present[b]\n",
      "Month,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec,Year\n",
      "Record high °F (°C),72(22),78(26),86(30),96(36),99(37),101(38),106(41),104(40),102(39),94(34),84(29),75(24),106(41)\n",
      "Mean maximum °F (°C),59.6(15.3),60.7(15.9),71.5(21.9),83.0(28.3),88.0(31.1),92.3(33.5),95.4(35.2),93.7(34.3),88.5(31.4),78.8(26.0),71.3(21.8),62.2(16.8),97.0(36.1)\n",
      "Average high °F (°C),38.3(3.5),41.6(5.3),49.7(9.8),61.2(16.2),70.8(21.6),79.3(26.3),84.1(28.9),82.6(28.1),75.2(24.0),63.8(17.7),53.8(12.1),43.0(6.1),62.0(16.7)\n",
      "Average low °F (°C),26.9(-2.8),28.9(-1.7),35.2(1.8),44.8(7.1),54.0(12.2),63.6(17.6),68.8(20.4),67.8(19.9),60.8(16.0),50.0(10.0),41.6(5.3),32.0(0.0),48.0(8.9)\n",
      "Mean minimum °F (°C),9.2(-12.7),12.8(-10.7),18.5(-7.5),32.3(0.2),43.5(6.4),52.9(11.6),60.3(15.7),58.8(14.9),48.6(9.2),38.0(3.3),27.7(-2.4),15.6(-9.1),7.0(-13.9)\n",
      "Record low °F (°C),-6(-21),-15(-26),3(-16),12(-11),32(0),44(7),52(11),50(10),39(4),28(-2),5(-15),-13(-25),-15(-26)\n",
      "Average precipitation inches (mm),3.65(93),3.09(78),4.36(111),4.50(114),4.19(106),4.41(112),4.60(117),4.44(113),4.28(109),4.40(112),4.02(102),4.00(102),49.94(1,268)\n",
      "Average snowfall inches (cm),7.0(18),9.2(23),3.9(9.9),0.6(1.5),0(0),0(0),0(0),0(0),0(0),0(0),0.3(0.76),4.8(12),25.8(66)\n",
      "Average precipitation days (- 0.01 in),10.4,9.2,10.9,11.5,11.1,11.2,10.4,9.5,8.7,8.9,9.6,10.6,122.0\n",
      "Average snowy days (- 0.1 in),4.0,2.8,1.8,0.3,0,0,0,0,0,0,0.2,2.3,11.4\n",
      "Average relative humidity (%),61.5,60.2,58.5,55.3,62.7,65.2,64.2,66.0,67.8,65.6,64.6,64.1,63.0\n",
      "Mean monthly sunshine hours,162.7,163.1,212.5,225.6,256.6,257.3,268.2,268.2,219.3,211.2,151.0,139.0,2,534.7\n",
      "Percent possible sunshine,54,55,57,57,57,57,59,63,59,61,51,48,57\n",
      "Average ultraviolet index,2,3,4,6,7,8,8,8,6,4,2,1,5\n",
      "Source #1: NOAA (relative humidity and sun 1961–1990)[237][249][233][250]\n",
      "\n",
      "See Geography of New York City for additional climate information from the outer boroughs.\n",
      "\n",
      "City compared to State & U.S.\n",
      "2010 Census[270][271],NY City,NY State,U.S.\n",
      "Total population,8,175,133,19,378,102,308,745,538\n",
      "Population change, 2000 to 2010,+2.1%,+2.1%,+9.7%\n",
      "Population density (people/sqmi),27,012.5,411.2,87.4\n",
      "Median household income (2015),$53,373,$59,269,$53,889\n",
      "Bachelor's degree or higher,35.7%,34.2%,29.8%\n",
      "Foreign born,37.2%,22.5%,13.2%\n",
      "White (non-Hispanic),44.0%,65.7%,72.4%\n",
      "Black,25.5%,15.9%,12.6%\n",
      "Hispanic (any race),28.6%,17.6%,16.3%\n",
      "Asian,12.7%,7.3%,4.8%\n",
      "\n",
      "Racial composition,2010[270],1990[272],1970[272],1940[272]\n",
      "White,44.0%,52.3%,76.6%,93.6%\n",
      "—Non-Hispanic,33.3%,43.2%,62.9%[273],92.0%\n",
      "Black or African American,25.5%,28.7%,21.1%,6.1%\n",
      "Hispanic or Latino (of any race),28.6%,24.4%,16.2%[273],1.6%\n",
      "Asian,12.7%,7.0%,1.2%,-\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "def table_content(tab):\n",
    "    d = []\n",
    "    fout = open('tab.txt', 'w', encoding='utf8')\n",
    "    for tr in tab.find_all('tr'):\n",
    "        for td in tr.find_all(['td', 'th']):\n",
    "            print(td.get_text().strip(), end=',', file = fout)\n",
    "        print('', file = fout)\n",
    "\n",
    "\n",
    "\n",
    "resp = urlopen('file:///C:/Users/user/PycharmProjects/pythonProject/html11.txt') # скачиваем файл\n",
    "html = resp.read() # считываем содержимое\n",
    "soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "table = soup.find_all('table', attrs={'class', \"wikitable collapsible collapsed\"})\n",
    "\n",
    "t1 = table_content(table[0])\n",
    "file = open('tab.txt', 'r', encoding = 'utf8')\n",
    "for line in file:\n",
    "    a = line.split(',')\n",
    "    print((',').join(a[:-1]).replace('?','-').replace('\\n',' '))\n",
    "print()\n",
    "\n",
    "t2 = table_content(table[1])\n",
    "file = open('tab.txt', 'r',encoding = 'utf8')\n",
    "for line in file:\n",
    "    a = line.split(',')\n",
    "    print((',').join(a[:-1]).replace('?','-'))\n",
    "print()\n",
    "t3 = table_content(table[2])\n",
    "file = open('tab.txt', 'r',encoding = 'utf8')\n",
    "for line in file:\n",
    "    a = line.split(',')\n",
    "    print((',').join(a[:-1]).replace('?','-'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a6c00c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate data for New York (Belvedere Castle, Central Park), 1981–2010 normals,[a] extremes 1869–present[b],\n",
      "Month,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec,Year,\n",
      "Record high °F (°C),72(22),78(26),86(30),96(36),99(37),101(38),106(41),104(40),102(39),94(34),84(29),75(24),106(41),\n",
      "Mean maximum °F (°C),59.6(15.3),60.7(15.9),71.5(21.9),83.0(28.3),88.0(31.1),92.3(33.5),95.4(35.2),93.7(34.3),88.5(31.4),78.8(26.0),71.3(21.8),62.2(16.8),97.0(36.1),\n",
      "Average high °F (°C),38.3(3.5),41.6(5.3),49.7(9.8),61.2(16.2),70.8(21.6),79.3(26.3),84.1(28.9),82.6(28.1),75.2(24.0),63.8(17.7),53.8(12.1),43.0(6.1),62.0(16.7),\n",
      "Average low °F (°C),26.9(-2.8),28.9(-1.7),35.2(1.8),44.8(7.1),54.0(12.2),63.6(17.6),68.8(20.4),67.8(19.9),60.8(16.0),50.0(10.0),41.6(5.3),32.0(0.0),48.0(8.9),\n",
      "Mean minimum °F (°C),9.2(-12.7),12.8(-10.7),18.5(-7.5),32.3(0.2),43.5(6.4),52.9(11.6),60.3(15.7),58.8(14.9),48.6(9.2),38.0(3.3),27.7(-2.4),15.6(-9.1),7.0(-13.9),\n",
      "Record low °F (°C),-6(-21),-15(-26),3(-16),12(-11),32(0),44(7),52(11),50(10),39(4),28(-2),5(-15),-13(-25),-15(-26),\n",
      "Average precipitation inches (mm),3.65(93),3.09(78),4.36(111),4.50(114),4.19(106),4.41(112),4.60(117),4.44(113),4.28(109),4.40(112),4.02(102),4.00(102),49.94(1,268),\n",
      "Average snowfall inches (cm),7.0(18),9.2(23),3.9(9.9),0.6(1.5),0(0),0(0),0(0),0(0),0(0),0(0),0.3(0.76),4.8(12),25.8(66),\n",
      "Average precipitation days (- 0.01 in),10.4,9.2,10.9,11.5,11.1,11.2,10.4,9.5,8.7,8.9,9.6,10.6,122.0,\n",
      "Average snowy days (- 0.1 in),4.0,2.8,1.8,0.3,0,0,0,0,0,0,0.2,2.3,11.4,\n",
      "Average relative humidity (%),61.5,60.2,58.5,55.3,62.7,65.2,64.2,66.0,67.8,65.6,64.6,64.1,63.0,\n",
      "Mean monthly sunshine hours,162.7,163.1,212.5,225.6,256.6,257.3,268.2,268.2,219.3,211.2,151.0,139.0,2,534.7,\n",
      "Percent possible sunshine,54,55,57,57,57,57,59,63,59,61,51,48,57,\n",
      "Average ultraviolet index,2,3,4,6,7,8,8,8,6,4,2,1,5,\n",
      "Source #1: NOAA (relative humidity and sun 1961–1990)[237][249][233][250],\n",
      "Source #2: Weather Atlas[251]\n",
      "See Geography of New York City for additional climate information from the outer boroughs.,\n",
      "\n",
      "City compared to State & U.S.,\n",
      "2010 Census[270][271],NY City,NY State,U.S.,\n",
      "Total population,8,175,133,19,378,102,308,745,538,\n",
      "Population change, 2000 to 2010,+2.1%,+2.1%,+9.7%,\n",
      "Population density (people/sqmi),27,012.5,411.2,87.4,\n",
      "Median household income (2015),$53,373,$59,269,$53,889,\n",
      "Bachelor's degree or higher,35.7%,34.2%,29.8%,\n",
      "Foreign born,37.2%,22.5%,13.2%,\n",
      "White (non-Hispanic),44.0%,65.7%,72.4%,\n",
      "Black,25.5%,15.9%,12.6%,\n",
      "Hispanic (any race),28.6%,17.6%,16.3%,\n",
      "Asian,12.7%,7.3%,4.8%,\n",
      "\n",
      "Racial composition,2010[270],1990[272],1970[272],1940[272],\n",
      "White,44.0%,52.3%,76.6%,93.6%,\n",
      "—Non-Hispanic,33.3%,43.2%,62.9%[273],92.0%,\n",
      "Black or African American,25.5%,28.7%,21.1%,6.1%,\n",
      "Hispanic or Latino (of any race),28.6%,24.4%,16.2%[273],1.6%,\n",
      "Asian,12.7%,7.0%,1.2%,-,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "def table_content(tab):\n",
    "    d = []\n",
    "    fout = open('tab.txt', 'w', encoding='utf8')\n",
    "    for tr in tab.find_all('tr'):\n",
    "        for td in tr.find_all(['td', 'th']):\n",
    "            print(td.get_text().strip().replace('?','-'), end=',')\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "resp = urlopen('file:///C:/Users/user/PycharmProjects/pythonProject/html11.txt') # скачиваем файл\n",
    "html = resp.read() # считываем содержимое\n",
    "soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "table = soup.find_all('table', attrs={'class', \"wikitable collapsible collapsed\"})\n",
    "t1 = table_content(table[0])\n",
    "t2 = table_content(table[1])\n",
    "t3 = table_content(table[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b886ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "else except finally "
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "resp = urlopen('file:///C:/Users/user/PycharmProjects/pythonProject/html9.txt') # скачиваем файл\n",
    "html = resp.read() # считываем содержимое\n",
    "soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "#table = soup.find('table', attrs = {'class' : 'wikitable sortable'})\n",
    "cite = []\n",
    "d={}\n",
    "cnt_m = 0\n",
    "for link in soup.find_all('code'):\n",
    "    cite.append(str(link)[6:-7])\n",
    "#print(cite)\n",
    "for i in range(len(cite)):\n",
    "    cnt = cite.count(cite[i])\n",
    "    a = cite[i]\n",
    "    d[a] = cnt\n",
    "    if cnt>=cnt_m:\n",
    "        cnt_m=cnt\n",
    "print(cnt_m)\n",
    "b = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(len(b)):\n",
    "    if int(b[i][1]) == cnt_m:\n",
    "        print(b[i][0], end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb5ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
